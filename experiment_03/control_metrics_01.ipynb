{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows from rotate_no_resize_inference and running the nn-Unet model. It is used to find the Dice and sDice metric results. This script is to calculate the DICE, sDICE, and the Hausdorff distance of two sets of labels. The sets of labels are called (a) original for the manual labels and (b) predicted for the predicted labels\n",
    "Documentation of metrics can be found here: https://github.com/deepmind/surface-distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from ast import Break\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from absl.testing import absltest\n",
    "from absl.testing import parameterized\n",
    "import surface_distance\n",
    "from surface_distance import metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all paths\n",
    "\n",
    "nnUnet_res= '/home/chloe/nnUNet_Results/Task603_SettingUp_Res'\n",
    "predicted_labels = 'results/control_results/control_predictions'\n",
    "rot_dir = '/results/control_results/control_images'\n",
    "\n",
    "# Define the path to where you store transformed data and where to store nnUnet data\n",
    "original_label_dir = 'data/labelsTs'\n",
    "transformed_labels = 'results/control_results/control_labels'\n",
    "stored_control_labels = 'results/control_results/stored_control_labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run two below if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the results to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe add to only move image outputs\n",
    "file_names = os.listdir(nnUnet_res)\n",
    "\n",
    "#Make list of strings to create directory: original, control_image, load_save\n",
    "control_names = ['original', 'control', 'load_save']\n",
    "\n",
    "for file_name in file_names:\n",
    "    for name in control_names:\n",
    "        stored_rot_path = os.path.join(predicted_labels,name)\n",
    "        if not os.path.exists(stored_rot_path):\n",
    "            os.makedirs(stored_rot_path)\n",
    "        if name == 'original':\n",
    "            if file_name.endswith(\"pre.nii.gz\"):\n",
    "                shutil.copy(os.path.join(nnUnet_res, file_name), stored_rot_path)\n",
    "        if file_name.endswith(name+\"_image_0.0_0.0_0.0.nii.gz\"):\n",
    "            shutil.copy(os.path.join(nnUnet_res, file_name), stored_rot_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move transformed manual labels into folder for computing Dice and sDice metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied\n"
     ]
    }
   ],
   "source": [
    "#Store original, untransformed labels\n",
    "original_labels = os.listdir(original_label_dir)\n",
    "stored_orig_path = os.path.join(stored_control_labels,'original')\n",
    "if not os.path.exists(stored_orig_path):\n",
    "            os.makedirs(stored_orig_path)\n",
    "\n",
    "for label in original_labels:\n",
    "    shutil.copy(os.path.join(original_label_dir, label), stored_orig_path)\n",
    "\n",
    "patient_names = os.listdir(transformed_labels)\n",
    "\n",
    "#Store transformed control labels\n",
    "for patient in patient_names:\n",
    "    patient_path = os.path.join(transformed_labels, patient)\n",
    "    files = os.listdir(patient_path)\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\"control_label_0.0_0.0_0.0.nii.gz\"):\n",
    "            stored_rot_path = os.path.join(stored_control_labels,'control')\n",
    "            if not os.path.exists(stored_rot_path):\n",
    "                os.makedirs(stored_rot_path)\n",
    "            shutil.copy(os.path.join(patient_path, file_name), stored_rot_path)\n",
    "        if file_name.endswith(\"load_save_label_0.0_0.0_0.0.nii.gz\"):\n",
    "            stored_rot_path = os.path.join(stored_control_labels,'load_save')\n",
    "            if not os.path.exists(stored_rot_path):\n",
    "                os.makedirs(stored_rot_path)\n",
    "            shutil.copy(os.path.join(patient_path, file_name), stored_rot_path)\n",
    "\n",
    "print(\"Files copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give names for predicted labels and rotated manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over all the rotations\n",
    "\n",
    "transform_label_dir = transformed_labels\n",
    "stored_label_folder = stored_control_labels\n",
    "\n",
    "original_label_path = stored_label_folder \n",
    "predicted_label_path = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set initial values and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_np_array_of_single_structure(np_matrix, number):\n",
    "    single_struct_array = np.where(np_matrix != number, 0, np_matrix)\n",
    "    return single_struct_array.astype('bool')    # sets all 0-entries to False, and all others to True\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "num_structures = 1 + 1\n",
    "s_dice_tolerance = 2 #mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over file paths to obtain the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_numbers:  [0, 1]\n",
      "Predicting HN_P002_pre_0000_control_image_0.0_0.0_0.0.nii.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting HN_P003_pre_0000_control_image_0.0_0.0_0.0.nii.gz\n",
      "Predicting HN_P005_pre_0000_control_image_0.0_0.0_0.0.nii.gz\n",
      "Predicting HN_P002_pre_0000_load_save_image_0.0_0.0_0.0.nii.gz\n",
      "Predicting HN_P003_pre_0000_load_save_image_0.0_0.0_0.0.nii.gz\n",
      "Predicting HN_P005_pre_0000_load_save_image_0.0_0.0_0.0.nii.gz\n",
      "Predicting HN_P002_pre.nii.gz\n",
      "Predicting HN_P003_pre.nii.gz\n",
      "Predicting HN_P005_pre.nii.gz\n"
     ]
    }
   ],
   "source": [
    "dice_matrix = np.zeros(num_structures)\n",
    "hd_matrix = np.zeros(num_structures)\n",
    "avg_surface_d_matrix = np.zeros(num_structures)\n",
    "surf_dice_matrix = np.zeros(num_structures)\n",
    "\n",
    "num_patients = 0\n",
    "all_numbers = []\n",
    "for i in range(num_structures):\n",
    "    all_numbers.append(i)\n",
    "print(\"all_numbers: \", all_numbers)\n",
    "\n",
    "rot_list =  sorted_alphanumeric(os.listdir(predicted_label_path))\n",
    "first_file_list = sorted_alphanumeric(os.listdir(os.path.join(original_label_path, rot_list[0])))\n",
    "\n",
    "dice_array = np.zeros(((len(rot_list)), (len(first_file_list)))) #(rows, columns)\n",
    "sdice_array = np.zeros(((len(rot_list)), (len(first_file_list)))) #(rows, columns)\n",
    "\n",
    "rot_count = -1\n",
    "for rot in rot_list:\n",
    "    rot_count = rot_count + 1\n",
    "    rot_pred_path = os.path.join(predicted_label_path, rot)\n",
    "    rot_orig_path = os.path.join(original_label_path, rot)\n",
    "    file_count = -1\n",
    "    for filename in sorted_alphanumeric(os.listdir(rot_pred_path)):\n",
    "        print(\"Predicting\", filename)\n",
    "        file_count = file_count + 1\n",
    "        num_patients += 1\n",
    "        dice_arr = np.zeros(num_structures)\n",
    "        hd_arr = np.zeros(num_structures)\n",
    "        avg_surface_d_arr = np.zeros(num_structures)\n",
    "        surf_dice_arr = np.zeros(num_structures)\n",
    "\n",
    "        # extract the example name\n",
    "        # first split the path by '/' and take the last result to get the file name\n",
    "        # then exclude the last 7 characters to exclude the '.nii.gz'\n",
    "        name = filename.split('/')[-1][:-7]\n",
    "\n",
    "\n",
    "        ############ ORIGINAL ############\n",
    "\n",
    "        # read the label file and save it as nifti with correct naming\n",
    "        orig_name = name.replace(\"0000_\",\"\")\n",
    "        orig_name = orig_name.replace(\"image\",\"label\")\n",
    "        original_data_path = rot_orig_path + \"/\" +  orig_name + \".nii.gz\"\n",
    "        original_img = sitk.ReadImage(original_data_path)  # read the file (file is the path to the label file)\n",
    "        original_arr = sitk.GetArrayFromImage(original_img)\n",
    "\n",
    "        # count amount of pixels with different labels\n",
    "        unique, counts = np.unique(original_arr, return_counts=True)\n",
    "\n",
    "        ############ PREDICTIONS ############\n",
    "\n",
    "        # do the same for the corresponding image file\n",
    "        pred_data_path = rot_pred_path + \"/\" +  name + \".nii.gz\"\n",
    "        pred_img = sitk.ReadImage(pred_data_path)  # exchange the _labels with _predictions in the file name to get the path to the predictions and reads the predictions\n",
    "        pred_arr = sitk.GetArrayFromImage(pred_img)                 \n",
    "\n",
    "        # count amount of pixels with different labels\n",
    "        unique2, counts2 = np.unique(pred_arr, return_counts=True)\n",
    "\n",
    "    #for each structure\n",
    "        for number in range(num_structures):\n",
    "\n",
    "            # no evalutation for background\n",
    "            if(number == 0): continue\n",
    "\n",
    "            if(number in unique2):\n",
    "                #print(\"Analyzing structure: \", number)\n",
    "                original_structure = generate_np_array_of_single_structure(original_arr, number)\n",
    "                predicted_structure = generate_np_array_of_single_structure(pred_arr, number)\n",
    "\n",
    "                # 3rd agument spacing_mm: resp. 3-element list-like structure. Voxel spacing in x0, x1 and x2 directions.\n",
    "                surf_dist = metrics.compute_surface_distances(original_structure, predicted_structure, [3, 1, 1])\n",
    "                dice = metrics.compute_dice_coefficient(original_structure, predicted_structure)\n",
    "\n",
    "                # 2nd argument: percent: a float value between 0 and 100\n",
    "                hd = metrics.compute_robust_hausdorff(surf_dist, 99)\n",
    "                avg_sd = metrics.compute_average_surface_distance(surf_dist)\n",
    "                s_dice = metrics.compute_surface_dice_at_tolerance(surf_dist, s_dice_tolerance)\n",
    "\n",
    "                dice_arr[number] = dice\n",
    "                hd_arr[number] = hd\n",
    "                surf_dice_arr[number] = s_dice\n",
    "\n",
    "            else: \n",
    "                # check if a predicted structure is missing\n",
    "                print(\"missing structure in prediction: \", number)\n",
    "\n",
    "\n",
    "            #Fill in array for each file (each row = rotation, each column = patient )\n",
    "            dice_array[rot_count,file_count] = dice_arr[1]\n",
    "            sdice_array[rot_count,file_count] = surf_dice_arr[1]\n",
    "\n",
    "            dice_matrix = np.vstack((dice_matrix, dice_arr))\n",
    "            hd_matrix = np.vstack((hd_matrix, hd_arr))\n",
    "            #avg_surface_d_matrix = np.vstack(avg_surface_d_matrix, avg_surface_d_arr)\n",
    "            surf_dice_matrix = np.vstack((surf_dice_matrix, surf_dice_arr))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['control', 'load_save', 'original']\n",
      "['HN_P002', 'HN_P003', 'HN_P005']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "short_rot_list = rot_list\n",
    "print(short_rot_list)\n",
    "\n",
    "short_file_list = [s.replace('_pre_control_label_0.0_0.0_0.0.nii.gz','') for s in first_file_list]\n",
    "print(short_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Dice and sDice arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice:\n",
      "            HN_P002   HN_P003   HN_P005\n",
      "control    0.607047  0.604077  0.603476\n",
      "load_save  0.629938  0.623759  0.605366\n",
      "original   0.629938  0.623759  0.605366\n",
      "sDice:\n",
      "            HN_P002   HN_P003   HN_P005\n",
      "control    0.345861  0.409941  0.467537\n",
      "load_save  0.371993  0.438963  0.487433\n",
      "original   0.371993  0.438963  0.487433\n"
     ]
    }
   ],
   "source": [
    "print(\"Dice:\")\n",
    "dice_table = pd.DataFrame(dice_array, columns = short_file_list, index=short_rot_list).sort_index()\n",
    "print(dice_table)\n",
    "\n",
    "print(\"sDice:\")\n",
    "sdice_table = pd.DataFrame(sdice_array, columns = short_file_list, index=short_rot_list).sort_index()\n",
    "print(sdice_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
